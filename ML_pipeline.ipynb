{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the pipeline...\n",
      "Loading and preprocessing data...\n",
      "Data loaded and preprocessed successfully.\n",
      "Number of classes in the dataset: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Global variables for hyperparameters\n",
    "LOGISTIC_REGRESSION_PARAMS = {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear'], 'max_iter': [1000]}\n",
    "LDA_PARAMS = {'solver': ['svd', 'lsqr']}\n",
    "QDA_PARAMS = {}\n",
    "KNN_PARAMS = {'n_neighbors': [3, 5, 7]}\n",
    "DECISION_TREE_PARAMS = {'max_depth': [3, 5, 7]}\n",
    "RANDOM_FOREST_PARAMS = {'n_estimators': [50, 100], 'max_depth': [3, 5, 7]}\n",
    "EXTRA_TREES_PARAMS = {'n_estimators': [50, 100], 'max_depth': [3, 5, 7]}\n",
    "GRADIENT_BOOSTING_PARAMS = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "XGBOOST_PARAMS = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "LIGHTGBM_PARAMS = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'verbose': [-1]}\n",
    "CATBOOST_PARAMS = {'iterations': [50, 100], 'learning_rate': [0.01, 0.1], 'depth': [3, 5]}\n",
    "SVM_PARAMS = {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']}\n",
    "NU_SVC_PARAMS = {'nu': [0.1, 0.5], 'kernel': ['rbf', 'linear']}\n",
    "LINEAR_SVC_PARAMS = {'C': [0.1, 1, 10]}\n",
    "GAUSSIAN_NB_PARAMS = {}\n",
    "MLP_PARAMS = {'hidden_layer_sizes': [(50,), (100,)], 'max_iter': [500, 1000]}\n",
    "GAUSSIAN_PROCESS_PARAMS = {'max_iter_predict': [100], 'kernel': [1.0 * RBF(1.0)]}\n",
    "SGD_PARAMS = {'max_iter': [500, 1000], 'tol': [1e-3, 1e-4]}\n",
    "PASSIVE_AGGRESSIVE_PARAMS = {'C': [0.1, 1, 10], 'max_iter': [500, 1000], 'tol': [1e-3, 1e-4]}\n",
    "PERCEPTRON_PARAMS = {'max_iter': [500, 1000], 'tol': [1e-3, 1e-4]}\n",
    "RIDGE_PARAMS = {'alpha': [0.1, 1, 10]}\n",
    "BAGGING_PARAMS = {'n_estimators': [5, 10]}\n",
    "ADABOOST_PARAMS = {'n_estimators': [50, 100], 'learning_rate': [0.1, 1.0]}\n",
    "HISTOGRAM_GBM_PARAMS = {'max_iter': [50, 100], 'learning_rate': [0.1, 1.0]}\n",
    "\n",
    "# Flag to enable grid search\n",
    "ENABLE_GRID_SEARCH = False\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(file_path):\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        X = data.drop('label', axis=1)\n",
    "        y = data['label']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        print(\"Data loaded and preprocessed successfully.\")\n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    except Exception as e:\n",
    "        print(f\"Error in loading and preprocessing data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name, params):\n",
    "    print(f\"Training and evaluating {model_name}...\")\n",
    "    try:\n",
    "        if ENABLE_GRID_SEARCH and hasattr(model, 'get_params'):\n",
    "            try:\n",
    "                grid_search = GridSearchCV(model, params, cv=5, n_jobs=-1)\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                model = grid_search.best_estimator_\n",
    "                print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Grid search failed for {model_name}: {str(e)}\")\n",
    "                print(\"Falling back to default parameters.\")\n",
    "                model.fit(X_train, y_train)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{model_name} trained and evaluated successfully. Accuracy: {accuracy:.4f}\")\n",
    "        return model, accuracy, report\n",
    "    except Exception as e:\n",
    "        print(f\"Error in training and evaluating {model_name}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Function to save model\n",
    "def save_model(model, model_name, params):\n",
    "    print(f\"Saving {model_name}...\")\n",
    "    try:\n",
    "        if not os.path.exists('Models'):\n",
    "            os.makedirs('Models')\n",
    "        param_str = '_'.join([f\"{k}_{v}\" for k, v in params.items() if k != 'estimators'])[:100]  # Limit filename length\n",
    "        filename = f\"Models/{model_name}_{param_str}.joblib\"\n",
    "        joblib.dump(model, filename)\n",
    "        print(f\"{model_name} saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in saving {model_name}: {str(e)}\")\n",
    "\n",
    "# Function to create VotingClassifier\n",
    "def create_voting_classifier(X_train, y_train):\n",
    "    estimators = []\n",
    "    for name, model in [('lr', LogisticRegression()), ('rf', RandomForestClassifier()), ('svm', SVC())]:\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            estimators.append((name, model))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting {name} for VotingClassifier: {str(e)}\")\n",
    "    return VotingClassifier(estimators=estimators)\n",
    "\n",
    "# Main pipeline function\n",
    "def run_pipeline(input_file):\n",
    "    print(\"Starting the pipeline...\")\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = load_and_preprocess_data(input_file)\n",
    "        \n",
    "        # Check number of classes\n",
    "        n_classes = len(np.unique(y_train))\n",
    "        print(f\"Number of classes in the dataset: {n_classes}\")\n",
    "        if n_classes < 2:\n",
    "            raise ValueError(\"The dataset must contain at least 2 classes for classification tasks.\")\n",
    "        \n",
    "        models = [\n",
    "            (LogisticRegression(), \"LogisticRegression\", LOGISTIC_REGRESSION_PARAMS),\n",
    "            (LinearDiscriminantAnalysis(), \"LDA\", LDA_PARAMS),\n",
    "            (QuadraticDiscriminantAnalysis(), \"QDA\", QDA_PARAMS),\n",
    "            (KNeighborsClassifier(), \"KNN\", KNN_PARAMS),\n",
    "            (DecisionTreeClassifier(), \"DecisionTree\", DECISION_TREE_PARAMS),\n",
    "            (RandomForestClassifier(), \"RandomForest\", RANDOM_FOREST_PARAMS),\n",
    "            (ExtraTreesClassifier(), \"ExtraTrees\", EXTRA_TREES_PARAMS),\n",
    "            (GradientBoostingClassifier(), \"GradientBoosting\", GRADIENT_BOOSTING_PARAMS),\n",
    "            (XGBClassifier(), \"XGBoost\", XGBOOST_PARAMS),\n",
    "            (LGBMClassifier(), \"LightGBM\", LIGHTGBM_PARAMS),\n",
    "            (CatBoostClassifier(verbose=False), \"CatBoost\", CATBOOST_PARAMS),\n",
    "            (SVC(), \"SVM\", SVM_PARAMS),\n",
    "            (NuSVC(), \"NuSVC\", NU_SVC_PARAMS),\n",
    "            (LinearSVC(), \"LinearSVC\", LINEAR_SVC_PARAMS),\n",
    "            (GaussianNB(), \"GaussianNB\", GAUSSIAN_NB_PARAMS),\n",
    "            (MLPClassifier(), \"MLP\", MLP_PARAMS),\n",
    "            (GaussianProcessClassifier(), \"GaussianProcess\", GAUSSIAN_PROCESS_PARAMS),\n",
    "            (SGDClassifier(), \"SGD\", SGD_PARAMS),\n",
    "            (PassiveAggressiveClassifier(), \"PassiveAggressive\", PASSIVE_AGGRESSIVE_PARAMS),\n",
    "            (Perceptron(), \"Perceptron\", PERCEPTRON_PARAMS),\n",
    "            (RidgeClassifier(), \"Ridge\", RIDGE_PARAMS),\n",
    "            (create_voting_classifier(X_train, y_train), \"Voting\", {}),\n",
    "            (BaggingClassifier(), \"Bagging\", BAGGING_PARAMS),\n",
    "            (AdaBoostClassifier(), \"AdaBoost\", ADABOOST_PARAMS),\n",
    "            (HistGradientBoostingClassifier(), \"HistGradientBoosting\", HISTOGRAM_GBM_PARAMS),\n",
    "        ]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for model, model_name, params in models:\n",
    "            try:\n",
    "                trained_model, accuracy, report = train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name, params)\n",
    "                if trained_model is not None:\n",
    "                    save_model(trained_model, model_name, params)\n",
    "                    results.append({\n",
    "                        'Model': model_name,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'Report': report\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while processing {model_name}: {str(e)}\")\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_df.to_csv(f\"Results_{timestamp}.csv\", index=False)\n",
    "        print(f\"Results saved to Results_{timestamp}.csv\")\n",
    "        print(\"Pipeline completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in running the pipeline: {str(e)}\")\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"../dataset/final_dataset.csv\"  \n",
    "    run_pipeline(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "622981     True\n",
      "622982     True\n",
      "622983     True\n",
      "622984     True\n",
      "622985     True\n",
      "Name: label, Length: 622986, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(input_file)\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "print(np.isnan(y))\n",
    "\n",
    "# print(\"Indices of NaN values:\", nan_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
